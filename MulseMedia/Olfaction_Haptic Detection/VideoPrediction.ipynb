{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VideoPrediction.ipynb","provenance":[{"file_id":"1loBAT6-IyucdaqeM3BaOVji3f_QPkzTC","timestamp":1586343337663}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Mb3qrSKxb9ZV","executionInfo":{"status":"ok","timestamp":1613757361696,"user_tz":0,"elapsed":3045,"user":{"displayName":"John Patrick Sexton","photoUrl":"","userId":"09133046963923236330"}}},"source":["#import all necessary library\n","\n","import torch\n","from torch.autograd import Variable as V\n","import torchvision.models as models\n","from torchvision import transforms as trn\n","from torch.nn import functional as F\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from torchvision.datasets.utils import download_file_from_google_drive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import os\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import cv2\n","import json\n","\n","#run the model predictions \n","device = 'cuda'\n","\n","# 1. Authenticate and create the PyDrive client\n","# request access to google drive \n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","#specify the architecture to download and use for predictions \n","arch = 'resnet18'\n","#run the model predictions on the GPU\n","device = 'cuda'\n","\n","# load the pre-trained weights\n","model_file = '%s_places365.pth.tar' % arch\n","if not os.access(model_file, os.W_OK):\n","    weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n","    os.system('wget ' + weight_url)\n","\n","#model_file = '/content/NormalizedResnet18.pth.tar'\n","#load the model\n","model = models.__dict__[arch](num_classes=365)\n","checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n","state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n","model.load_state_dict(state_dict)\n","model.to(device)\n","model.eval()\n","\n","\n","# image transformer to crop, normalize and, and convert to tensor\n","centre_crop = trn.Compose([\n","        trn.Resize((256,256)),\n","        trn.CenterCrop(224),\n","        trn.ToTensor(),\n","        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","\n","\n","# load the class label with mulse media encoding\n","file_name = 'categories_places365.txt'\n","\n","if not os.access(file_name, os.W_OK):\n","    synset_url = 'https://raw.githubusercontent.com/sextonj5/MulseRepos/master/categories_places365.txt'\n","    os.system('wget ' + synset_url)\n","classes = list()\n","\n","\n","with open(file_name) as class_file:\n","    for line in class_file:\n","        classes.append(line.strip().split(' '))\n","classes = tuple(classes)\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"m7ol8oOnHeE2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613757369855,"user_tz":0,"elapsed":3052,"user":{"displayName":"John Patrick Sexton","photoUrl":"","userId":"09133046963923236330"}},"outputId":"be1e7f49-faee-4ffc-d510-16894f5f363b"},"source":["!pip install pydub\n","!mkdir Olfaction/\n","!mkdir Haptic/"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting pydub\n","  Downloading https://files.pythonhosted.org/packages/7b/d1/fbfa79371a8cd9bb15c2e3c480d7e6e340ed5cc55005174e16f48418333a/pydub-0.24.1-py2.py3-none-any.whl\n","Installing collected packages: pydub\n","Successfully installed pydub-0.24.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7scO2quq_24S","executionInfo":{"status":"ok","timestamp":1613757373418,"user_tz":0,"elapsed":531,"user":{"displayName":"John Patrick Sexton","photoUrl":"","userId":"09133046963923236330"}}},"source":["\n","def writeHapJSON(start,duration,HapticNum):    \n","#structure of the JSON output \n","    values = {\n","  \"start\": HapticNum*10,\n","  \"type\": \"real\",\n","  \"number\": HapticNum,\n","  \"effect\": \"haptic\",\n","  \"haptic_effects\": [\n","\t{\n","      \"start\": start,\n","      \"description\":{\n","          \"pattern\":[\n","                     {\n","                      \"type\": \"custom\",\n","                      \"length-ms\": duration   \n","                     }\n","          ],\n","          \"rate\": {\n","              \"frequency\":0\n","          }\n","      }\n","    }\n","  ]\n","}\n","\n","#write \"values\" JSON string to the JSON file \n","    with open('Haptic/Hnewt_' + str(HapticNum) + '.json', 'w') as f:\n","        json.dump(values, f, sort_keys=False, indent=2)\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"A7gcDVsqjc5O","executionInfo":{"status":"ok","timestamp":1613757882155,"user_tz":0,"elapsed":521,"user":{"displayName":"John Patrick Sexton","photoUrl":"","userId":"09133046963923236330"}}},"source":["#number of json files produced\n","#one produced every 10 seconds\n","jsonNum = 0\n","#whats in each olfaction slot\n","fans = ['o','x','d','a']\n","#list of 10 detections when full sent to the json file function\n","HapticNum = 0\n","Olfaction = list()\n","    \n","#this function is called when a ten second block of Olfaction data has been \n","#created, the 10 seconds of media is passed to this function and stores\n","#the mulsemedia content to a Json file\n","def writeOlfJSON(smell,jsonNum):\n","#arrays detailing how long the smell should be played for and when the smell \n","#starts playing inside the 10 second window\n","    fanCount = [0,0,0,0]    \n","    fanFirst = [0,0,0,0]\n","    n = 0\n","    for i in range(0,10):\n","        if (smell[i] == fans[0]):\n","            fanCount[0]+=1\n","            if (fanFirst[0] == 0):\n","                fanFirst[0]=i\n","        elif(smell[i] == fans[1]):\n","            fanCount[1]+=1\n","            if (fanFirst[1] == 0):\n","                fanFirst[1]=i\n","        elif(smell[i] == fans[2]):\n","            fanCount[2]+=1\n","            if (fanFirst[2] == 0):\n","                fanFirst[2]=i\n","        elif(smell[i] == fans[3]):\n","            fanCount[3]+=1\n","            if (fanFirst[3] == 0):\n","                fanFirst[3]=i\n","        else:\n","            n+=1\n","    \n","    #fan number, start, duration all noted for JSON file string\n","    index = list.index(fanCount,max(fanCount))\n","    start = fanFirst[index]*1000\n","    duration = fanCount[index]*1000\n","    fannumber = index\n","\n","#structure of the JSON output \n","    values = {\n","  \"start\": jsonNum*10,\n","  \"type\": \"real\",\n","  \"number\": jsonNum,\n","  \"effect\": \"olfaction\",\n","  \"olfaction_effects\": [\n","\t{\n","      \"start\": start,\n","      \"duration\": str(duration),\n","      \"fan_number\": str(fannumber)\n","    }\n","  ]\n","}\n","\n","\n","#write \"values\" file to the JSON file \n","    with open('Olfaction/Onewt_' + str(jsonNum) + '.json', 'w') as f:\n","        json.dump(values, f, sort_keys=False, indent=2)\n","\n","\n","#splits up fram into six and makes combined prediction\n","def Split_Prediction(img):\n","#the width and height of the cropped images\n","    h = int(img.size[0]/3)\n","    w = int(img.size[1]/2)\n","\n","\n","#crop the image 4 times adding \n","    for j in range(0,3):\n","      for k in range(0,2):\n","      \n","        im1 = img.crop((h*(j) , w*k, h*(j+1) , w*(k+1)))\n","      \n","        input_img = V(centre_crop(im1).unsqueeze(0))\n","        \n","        #flip the back face to the right orientation\n","        if(j==1 and k==1):\n","          angle = 90\n","          im1 = im1.rotate(angle)\n","          \n","        # forward pass\n","        logit = model.forward(input_img.cuda())\n","        if(j == 0 and k == 0):\n","          h_xtemp = logit\n","        \n","        #Discard the ground and sky faces of the cube map\n","        elif((j==0 or j == 2) and k==1):\n","          pass\n","        #The other 4 faces get passed through the network\n","        else:\n","          h_xtemp = logit.add(h_xtemp)\n","\n","    #the softmax is applied on the final vector\n","    h_x = F.softmax(h_xtemp, 1).data.squeeze()\n","    return h_x\n","    #return h_xtemp\n","\n","\n","#gets a frame at the time in millisec (sec) passes frame to prediction function\n","\n","def getFrame(sec):\n","    #the array that contains 10 seconds worth of olfaction sensory information\n","    global Olfaction\n","    #reads a frame from the video at the time \"sec\" \n","    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec)\n","    hasFrames,image = vidcap.read()\n","    #image converted from an array to a PIL image \n","    im1 = Image.fromarray(image)\n","\n","    if hasFrames:\n","        #passes the frame to the prediction function which crops and makes predictions on that frame\n","        probs, idx = Split_Prediction(im1).sort(0, True)\n","        #prints the name of the video and the time the frame was taken\n","        #print('{} prediction on {}'.format(arch,fname) + ' at ' + str(sec/1000) + ' seconds')\n","        #the smell encoding from this prediction is added to the olfaction array\n","        Olfaction.extend(classes[idx[0]][2])\n","\n","        #when 10 predictions have been made dump it to the json file and start\n","        #filling the olfaction array again. \n","        #10 predictions is ten seconds worth of information\n","\n","        if(len(Olfaction) == 10):\n","            print(Olfaction)\n","            #10 seconds of olfaction information is written to a JSON file to store data\n","            writeOlfJSON(Olfaction,int(sec/10000))\n","            #once the information is stored in JSON the olfaction array is emptied\n","            Olfaction = []\n","\n","        # output the prediction\n","        #for i in range(0, 3):\n","         #   print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))\n","\n","    return hasFrames\n"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NA7JwiXNZKG6"},"source":[" \n","\n","1.   File is loaded in from drive directory (projectFourthYear)\n","2.   A frame is parsed every second using the getFrame function\n","\n","1.   This passes the frame to the prediction function\n","2.   the prediction is associated with one of the following\n","\n","\n","Ocean = o\n","Oak = a\n","Candy = c\n","Chococlate = x\n","Diesel = d\n","None = n\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"RPpodBMoeP-1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613758089360,"user_tz":0,"elapsed":202022,"user":{"displayName":"John Patrick Sexton","photoUrl":"","userId":"09133046963923236330"}},"outputId":"ef318102-5cb3-43c6-bec0-d91d6728f5d6"},"source":["from moviepy.editor import *\n","import librosa \n","import pydub\n","import time\n","\n","\n","#the array that contains 10 seconds worth of olfaction sensory information\n","Olfaction = list()\n","HapticNum = 0\n","\n","local_download_path = os.path.expanduser('~/data')\n","try:\n","  os.makedirs(local_download_path)\n","except: pass\n","\n","#video in drive folder\n","file_list = drive.ListFile(\n","    {'q': \"'1V6VLEBW-cyJLBFJe937oDrayvfasg9rO' in parents\"}).GetList()\n","for f in file_list:\n","  # 3. Create & download by id.\n","  print('title: %s, id: %s' % (f['title'], f['id']))\n","  fname = os.path.join(local_download_path, f['title'])\n","  print('downloading to {}'.format(fname))\n","  f_ = drive.CreateFile({'id': f['id']})\n","  f_.GetContentFile(fname)\n","\n","################################################################################\n","#read in the video and extract audio\n","  video = VideoFileClip(fname)\n","  audio = video.audio \n","  audio.write_audiofile(\"audio.wav\") \n","\n","#read in audio file\n","  aud = pydub.AudioSegment.from_wav(\"audio.wav\")\n","  lengthAud = aud.duration_seconds - aud.duration_seconds%10\n","  i = 0\n","\n","  while(i<lengthAud):\n","#save file into 10 second chunks\n","    temp = aud[i*1000:(i+10)*1000]\n","    z = \"Haptic/Sound_At_\"+str(i) + \"_Seconds\" + \".wav\"\n","    temp.export( z, format=\"wav\")\n","\n","    #videoaud is the audio sampled at 40000 hz\n","    #z is the input sound signal file\n","    videoaud, sr = librosa.core.load(z,sr=40000)\n","\n","\n","    # g is a 1x100 vector with the \"loudness\" of the signal every tenth of a second\n","    g = librosa.feature.rms(y=videoaud,frame_length=4000, hop_length=4000,center =False)\n","    start = round((np.argmax(np.squeeze(g))/len(np.squeeze(g)))*10 +i)\n","    \n","    #the threshold of the max value must be calibrated\n","    if(max(np.squeeze(g))>0.51):\n","      dur =  1000\n","    else: \n","      dur = 0\n","    \n","    #writes the haptic data to a JSON file\n","    HapticNum = HapticNum+1 \n","    writeHapJSON(start,dur,HapticNum)\n","    \n","    i= i+10\n","\n","################################################################################\n","  starttime = time.perf_counter()\n","  vidcap = cv2.VideoCapture(fname)\n","\n","\n","  #work out duration of video to know when to stop\n","  fps = vidcap.get(cv2.CAP_PROP_FPS)  \n","  frame_count = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n","  duration = int(1000*(frame_count/fps))\n","\n","  sec = 0\n","  print(vidcap.get(cv2.CAP_PROP_FPS))\n","  frameRate = 1000 #1 frame per second\n","  sec = 1000\n","  \n","  while (sec<(duration) and getFrame(sec)):\n","      #getFrame(sec)\n","      sec = sec + frameRate\n","      sec = round(sec, 2)\n","  \n","\n","  print(\"stopped detection\")\n","  endtime = time.perf_counter()\n","  print(endtime - starttime)\n","  break"],"execution_count":13,"outputs":[{"output_type":"stream","text":["title: RedwoodsWalkAmongGiants(360 Video).mp4, id: 1un6NRGE5cjE1x2gRifzaOgieK5o4d9kO\n","downloading to /root/data/RedwoodsWalkAmongGiants(360 Video).mp4\n","[MoviePy] Writing audio in audio.wav\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2655/2655 [00:00<00:00, 2844.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["[MoviePy] Done.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["30.0083176282629\n","['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'x']\n","['n', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n","['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n","['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n","['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n","['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n","['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n","['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n","['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n","['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n","['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n","['a', 'a', 'a', 'a', 'n', 'n', 'n', 'n', 'n', 'n']\n","stopped detection\n","193.00090177700008\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NgxqDQuo3rNk"},"source":["print(sec)\n","print(duration)"],"execution_count":null,"outputs":[]}]}